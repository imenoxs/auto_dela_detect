{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a0097dd8",
   "metadata": {},
   "source": [
    "# Image processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd78d239",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "from ipywidgets import *\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import transforms\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "import sys\n",
    "import glob\n",
    "import os\n",
    "import shutil\n",
    "import yaml\n",
    "\n",
    "configpath = \"configs/pipelin06config.yaml\"\n",
    "src_path = \"src/2303_pez500/imgdat/\"\n",
    "dst_path = \"dst/2303_pez500\"\n",
    "\n",
    "# useful functions\n",
    "def get_imagepath(path):\n",
    "    image_list = glob.glob(os.getcwd() + f\"/{path}/*.png\", recursive=True)\n",
    "    if image_list == []:\n",
    "            image_list = glob.glob(os.getcwd() + f\"/{path}/*.csv\", recursive=True)\n",
    "    image_list.sort()\n",
    "    return image_list\n",
    "\n",
    "def save_params(section,vals2save):\n",
    "    try:\n",
    "        with open(configpath, 'r') as file:\n",
    "            conf = yaml.safe_load(file)\n",
    "        if conf == None:\n",
    "            raise Exception(\"test\")\n",
    "    except: \n",
    "        conf = {\n",
    "            \"Paths\": {\n",
    "                \"srcpath\": \"./src\",\n",
    "                \"dstpath\": \"./dst\"\n",
    "            }\n",
    "        }\n",
    "    \n",
    "    sectionnotexistflag = False\n",
    "    try: sectionnotexistflag = section not in conf\n",
    "    except: pass\n",
    "    if sectionnotexistflag:\n",
    "        conf[section] = {}\n",
    "    for key, val in vals2save.items():\n",
    "        conf[section].update({key:val})\n",
    "\n",
    "    with open(configpath, 'w') as file:\n",
    "        yaml.dump(conf, file)\n",
    "        \n",
    "def gen_filename(path2folder, filename):\n",
    "        i = 0\n",
    "        try:\n",
    "            while os.path.exists(f\"{path2folder}/{filename}{i}.png\"):\n",
    "                i += 1\n",
    "        except: pass\n",
    "        return f\"{path2folder}/{filename}{i}.png\"\n",
    "    \n",
    "def load_img(impath):\n",
    "    \"\"\"\n",
    "    load_img \n",
    "    :param path: path to image\n",
    "    :param :\n",
    "    \"\"\"\n",
    "    try:\n",
    "        im = Image.open(impath)\n",
    "    except: \n",
    "        im = Image.fromarray(np.genfromtxt(impath, delimiter=\",\"))\n",
    "    finally: gray = im.convert('L')\n",
    "    #width, heigth = im.size\n",
    "    #im_array = np.array(gray.getdata()).reshape(heigth, width)\n",
    "    #df_im = pd.DataFrame(im_array)\n",
    "    return gray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "91e80cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if opencv/cv2 is not installed uncomment next line\n",
    "# pip install opencv-python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27b2400d",
   "metadata": {},
   "source": [
    "## Raw Images\n",
    "The raw mages have been retrieved with a ultrasonix ultrasound machine using a prototyp of a poly-CMUT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c68caaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1d10580c73d441281ff1a8a5b666ee3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='imagenr', max=509), Output()), _dom_classes=('widget-int…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Loading of the input image\n",
    "imlst = get_imagepath(src_path)\n",
    "@interact(imagenr=(0,len(imlst)-1))\n",
    "def show_img(imagenr=0):\n",
    "    im = load_img(imlst[imagenr])\n",
    "    _=plt.imshow(im)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5646082a",
   "metadata": {},
   "source": [
    "## Cropping Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "972fcffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def im2np(im):\n",
    "    width, heigth = im.size\n",
    "    im_array = np.array(im.getdata()).reshape(heigth, width)\n",
    "    return im_array\n",
    "def clean_dir(path):\n",
    "    try: shutil.rmtree(path)\n",
    "    except: pass\n",
    "    os.makedirs(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a675a4d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "def im_crop(im: Image = None, crop_dat: tuple = (0,0,0,0), mode: int = 1, path: str = None):\n",
    "    \"\"\"\n",
    "    im_crop can crop images using PIL.Image and can optionally save it to a path\n",
    "    \n",
    "    :param im: PIL:Image object that should be cropped\n",
    "    :param crop_dat: Tuple containing how many pixels to crop (left, top, right, bottom)\n",
    "    :param mode: Setting processing mode. 1 = returning PL.Image object; 2 = saving picture with same to path entered in path atribute\n",
    "    :param path: Path to save picture to\n",
    "    \"\"\"\n",
    "    left,top,right,bottom = crop_dat\n",
    "    width, height = im.size\n",
    "    im_crop = im.crop((left, top, width-right, height-bottom))\n",
    "    if mode == 1:\n",
    "        return im_crop\n",
    "    if mode == 2:\n",
    "        im_crop.save(gen_filename(path,\"image\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "84f79673",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac5abe6edbb84ffd991fa22ed00c63ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='left', max=327), IntSlider(value=0, description='right',…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "imglist = get_imagepath(src_path)\n",
    "hight, width = np.array(load_img(imglist[1])).shape\n",
    "left= IntSlider(min=0, max=width, step=1, value=0)\n",
    "top= IntSlider(min=0, max=hight, step=1, value=0)\n",
    "right= IntSlider(min=0, max=width, step=1, value=0)\n",
    "bottom= IntSlider(min=0, max=hight, step=1, value=0)\n",
    "pic= IntSlider(min=0, max=len(imglist)-1, step=1, value=0)\n",
    "\n",
    "\n",
    "def im_crop_caller(left,right,top,bottom, pic):\n",
    "    im = load_img(imglist[pic])\n",
    "    _=plt.imshow(im_crop(im, (left,top,right,bottom),1))\n",
    "    plt.axis('off')\n",
    "_=interact(im_crop_caller,left=left,top=top,right=right,bottom=bottom, pic=pic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "33b1a320",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save values to config.yaml\n",
    "vals2save={\n",
    "        \"left\": left.value,\n",
    "        \"top\": top.value,\n",
    "        \"right\": right.value,\n",
    "        \"bottom\": bottom.value\n",
    "    }\n",
    "save_params(\"Cropping\", vals2save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3a81a091",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert all pictures in imdata/raw\n",
    "dir_cropped= os.path.join(dst_path,\"cropped\")\n",
    "clean_dir(dir_cropped)\n",
    "image_list = get_imagepath(src_path)\n",
    "for pic in image_list:\n",
    "    im_crop(load_img(pic), (left.value,top.value,right.value,bottom.value),2,dir_cropped)\n",
    "src_path=dir_cropped"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ea258c3",
   "metadata": {},
   "source": [
    "## OpenCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5b3157a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4ee54b6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba8132020b354dcebefe6be03538fd3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=254, description='x', max=509), Output()), _dom_classes=('widget-interac…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "image_list = get_imagepath(src_path)\n",
    "image_list.sort()\n",
    "\n",
    "@interact(x=(0, len(image_list)-1))\n",
    "def sel_image(x):\n",
    "    global img\n",
    "    global img_gray\n",
    "    global img_rgb\n",
    "    img = cv2.imread(image_list[x])\n",
    "    img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    _=plt.imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78737d6a",
   "metadata": {},
   "source": [
    "## Thresholding\n",
    "#### Manual thresholding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2c57782a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trans_threshold(img_gray, thrval):\n",
    "    _, threshold = cv2.threshold(img_gray, thrval, 255, cv2.THRESH_BINARY)\n",
    "    return threshold\n",
    "\n",
    "thrval= IntSlider(min=0, max=255, step=1, value=200)\n",
    "def threshold(thrval):\n",
    "    plt.imshow(trans_threshold(img_gray, thrval))\n",
    "_=interact(threshold,thrval=thrval)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fe9359b",
   "metadata": {},
   "source": [
    "img_thr = trans_threshold(img_gray, thrval.value)\n",
    "_=plt.imshow(img_thr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7529b8cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_params(\"Thresholding\",{\"thrval\": thrval.value})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3ef23340",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tranform all images\n",
    "image_list = get_imagepath(src_path)\n",
    "dir_thr = os.path.join(dst_path, \"thresholded\")\n",
    "clean_dir(dir_thr)\n",
    "for pic in image_list:\n",
    "    im=cv2.imread(pic)\n",
    "    im_thr = trans_threshold(im, thrval.value)\n",
    "    plt.imsave(gen_filename(dir_thr,\"image\"), im_thr, format='png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abb1fe29",
   "metadata": {},
   "source": [
    "#### Otsu automatic thresholding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8bced6d5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "img_otsu=img_gray.copy()\n",
    "\n",
    "def otsu_tune():\n",
    "    x=10 #doesn't seem to cahnge anything at all\n",
    "    (T, im_otsu) = cv2.threshold(img_otsu, x, 255,cv2.THRESH_BINARY|cv2.THRESH_OTSU)\n",
    "    plt.imshow(im_otsu)\n",
    "_=otsu_tune()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2606ec66",
   "metadata": {},
   "source": [
    "### Summary threshold\n",
    "It seems like manual Thresholding is better\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48b8342d",
   "metadata": {},
   "source": [
    "## Drawing Edges on src image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7744c506",
   "metadata": {},
   "outputs": [],
   "source": [
    "imglstcrp = get_imagepath(dir_cropped)\n",
    "imglstthr = get_imagepath(dir_thr)\n",
    "imglstcrp.sort()\n",
    "imglstthr.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c093f553",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_contours(src=None,orig=None, nrconts=4):\n",
    "    src_gray = src.copy()\n",
    "    src_orig = orig.copy()\n",
    "    contours, hierarchy = cv2.findContours(src_gray, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    cnt=sorted(contours, key=cv2.contourArea)[0 if len(contours)<=nrconts else -nrconts-1:-1]\n",
    "    final_image = cv2.drawContours(src_orig,cnt, -1, (0, 255, 0), 2)\n",
    "    return final_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cd802cb7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nrconts=5\n",
    "imnr = 3\n",
    "img = cv2.imread(imglstcrp[imnr])\n",
    "img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "img_thr = cv2.imread(imglstthr[imnr])[:,:,2]\n",
    "_=plt.imshow(gen_contours(img_thr,img_rgb,nrconts=nrconts))\n",
    "save_params(\"Contour1\", {\"nrconts\": nrconts})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cad40286",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply threshold on all images\n",
    "dir_cont = os.path.join(dst_path,\"contour\")\n",
    "clean_dir(dir_cont)\n",
    "for picnr in range(len(imglstcrp)):\n",
    "    img = cv2.imread(imglstcrp[picnr])\n",
    "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img_thr = cv2.imread(imglstthr[picnr])[:,:,2]\n",
    "    \n",
    "    im_contour = gen_contours(img_thr,img_rgb,nrconts=nrconts)\n",
    "    plt.imsave(gen_filename(dir_cont,\"image\"), im_contour, format='png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f8b78a",
   "metadata": {},
   "source": [
    "### Erosion and Dilation\n",
    "1. Eliminating smaller noise patches by shrinking all the areas, so that only the larger ones, which more likely represent an error, stay left\n",
    "1. Evaluating several different kernels for dialating for best performance\n",
    "    - it seems best to only shrink vertically, because all the wanted areas are very slim and vanish quickly when shrinkung vertically\n",
    "    - Horisontal line kernel is beeing used for further processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "70cf5a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "v_kernel = np.array(\n",
    "[[0.,1.,0.],\n",
    " [0.,1.,0.],\n",
    " [0.,1.,0.]], np.uint8)\n",
    "h_kernel = np.array(\n",
    "    [[0.,0.,0.],\n",
    "     [1.,1.,1.],\n",
    "     [0.,0.,0.]],np.uint8)\n",
    "cross_kernel = np.array(\n",
    "    [[0.,1.,0.],\n",
    "     [1.,1.,1.],\n",
    "     [0.,1.,0.]],np.uint8)\n",
    "ones_kernel = np.ones((3,3))\n",
    "\n",
    "kernel = {\"vertical\":v_kernel, \"horizontal\": h_kernel, \"cross\": cross_kernel, \"square\":ones_kernel}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "deeeb2dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ero_dil(kernelnr=1,ero_iterations=4, dil_iterations=0, img_thr=None, img_orig=None):\n",
    "    global img_dilation\n",
    "    #kernel = np.ones((kernel, kernel), np.uint8)\n",
    "    kernel_name = list(kernel.keys())[kernelnr]\n",
    "    img_erosion = cv2.erode(img_thr, kernel[kernel_name], iterations=ero_iterations)\n",
    "    img_dilation = cv2.dilate(img_erosion, kernel[kernel_name], iterations=dil_iterations)\n",
    "    \n",
    "    fig, axs = plt.subplots(4)\n",
    "    _=axs[0].imshow(img_thr)\n",
    "    _=axs[0].set_title(f\"Threshold using {kernel_name} filter\")\n",
    "    _=axs[1].imshow(img_erosion)\n",
    "    _=axs[1].set_title(f\"Erosion\")\n",
    "    _=axs[2].imshow(img_dilation)\n",
    "    _=axs[2].set_title(\"Dilation\")\n",
    "    _=axs[3].imshow(gen_contours(img_dilation,img_orig))\n",
    "    _=axs[3].set_title(\"Original Image with drawn contour\")\n",
    "    fig.subplots_adjust(hspace=0.5)\n",
    "    for ax in axs:\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "20971255",
   "metadata": {},
   "outputs": [],
   "source": [
    "kernelnr = IntSlider(min=0, max=len(kernel)-1, step=1, value=1)\n",
    "ero_iterations = IntSlider(min=0, max=20, step=1, value=4)\n",
    "dil_iterations = IntSlider(min=0, max=20, step=1, value=4)\n",
    "img_nr = IntSlider(min=0, max=len(imglstthr), step=1, value=4)\n",
    "\n",
    "def ero_dil_caller(kernelnr=1,ero_iterations=4, dil_iterations=0, imgnr=3):\n",
    "    img_erodil = cv2.imread(imglstthr[imgnr])[:,:,2]\n",
    "    sel_image(imgnr)\n",
    "    plt.close(\"all\")\n",
    "    ero_dil(kernelnr=kernelnr, ero_iterations=ero_iterations,dil_iterations=dil_iterations, img_orig=img_rgb, img_thr=img_erodil)\n",
    "_=interact(ero_dil_caller,kernelnr=kernelnr, ero_iterations=ero_iterations,dil_iterations=dil_iterations, imgnr = img_nr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "df3b46fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "erodil_params = {\n",
    "    \"ero_iters\": ero_iterations.value,\n",
    "    \"dil_iters\": dil_iterations.value,\n",
    "    \"kernel\": kernelnr.value\n",
    "}\n",
    "save_params(\"Erodil\",erodil_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "70d5f463",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "edges = cv2.dilate(cv2.Canny(img_dilation,0,255),None)\n",
    "\n",
    "_=plt.imshow(edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3dd3a040",
   "metadata": {},
   "outputs": [],
   "source": [
    "conts=sorted(cv2.findContours(edges, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)[-2], key=cv2.contourArea)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58dece5c",
   "metadata": {},
   "source": [
    "Shows one closed shape at a time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "810c0aa3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "@interact(x=(0, len(conts)-1))\n",
    "def test(x):\n",
    "    mask = np.zeros(img_thr.shape, np.uint8)\n",
    "    masked = cv2.drawContours(mask,[conts[x]],-1,255,-1)\n",
    "    _ = plt.imshow(masked)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "988ed978",
   "metadata": {},
   "source": [
    "### Summary\n",
    "- dilation connects backplate with defect when close to backplate\n",
    "- erosion only on horizontal axis seems efficient\n",
    "- the more erosion the more likely it is to miss smaller defects"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a084eec7",
   "metadata": {},
   "source": [
    "# K-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba9055ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b21cd542",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_image = img\n",
    "img = cv2.cvtColor(sample_image,cv2.COLOR_BGR2RGB)\n",
    "_=plt.imshow(sample_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70d89453",
   "metadata": {},
   "outputs": [],
   "source": [
    "twoDimage = img.reshape((-1,3))\n",
    "twoDimage = np.float32(twoDimage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd537129",
   "metadata": {},
   "outputs": [],
   "source": [
    "criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 10, 1.0)\n",
    "K = 2\n",
    "attempts=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7536cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ret,label,center=cv2.kmeans(twoDimage,K,None,criteria,attempts,cv2.KMEANS_PP_CENTERS)\n",
    "center = np.uint8(center)\n",
    "res = center[label.flatten()]\n",
    "result_image = res.reshape((img.shape))\n",
    "\n",
    "_=plt.imshow(result_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "017518be",
   "metadata": {},
   "source": [
    "### Adding up pixel values for each row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "309531e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(\"dst/2303_pez500/thresholded/\")\n",
    "_ = plt.imshow(img)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7dd3f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(img[:,:,1])\n",
    "df.sum(axis=1).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2e0a4a5",
   "metadata": {},
   "source": [
    "### Siglan Processing (enhancement)\n",
    "#### Goal: Filter out noise to only have Front/Back plate and the Defect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef6625b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filterplate(signal):\n",
    "    \"\"\"\n",
    "    filterplate expects as input a 1d array of the sign of the first deviation,\n",
    "    of the accumulated rows vector and removes the first bump of the signal, which is assumed to be the front plate\n",
    "    \"\"\"\n",
    "    wobackfront = []\n",
    "    peakcnt = 0\n",
    "    flag = 0\n",
    "    for val in signal:\n",
    "        if peakcnt >= 1:\n",
    "            wobackfront.append(val)\n",
    "        else:\n",
    "            if val == -1:\n",
    "                flag = 1\n",
    "            if val in [0,1] and flag == 1:\n",
    "                peakcnt = 1\n",
    "                wobackfront.append(val)\n",
    "            else:\n",
    "                wobackfront.append(0)\n",
    "    return np.array(wobackfront)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a267689b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def imgProcess1(path_orig, path_thr, highttrash_perc=10, moving_average=10, savefig = False, filter_plate=True, outputpath = None):\n",
    "    \n",
    "    # loading binary and thresholded image as pandas dataframe\n",
    "    img = cv2.imread(path_thr)\n",
    "    img_orig=cv2.imread(path_orig)\n",
    "    df = pd.DataFrame(img[:,:,1])\n",
    "    \n",
    "    # Accumulating all Pixel values from image per row \n",
    "    plotdat=df.sum(axis=1)\n",
    "    \n",
    "    # reversing pandas series for better visualisation in plot down below\n",
    "    plotdatindex=plotdat.index\n",
    "    plotdat = plotdat.iloc[::-1]\n",
    "    plotdat.index = plotdatindex\n",
    "    \n",
    "    # calculating moving average to smoothen out curve\n",
    "    processed_dat=pd.Series(plotdat.rolling(moving_average).mean())\n",
    "\n",
    "    if True:\n",
    "        # threshold to filter out small peaks caused by noise\n",
    "        new_processed_dat = []\n",
    "        for val in processed_dat:\n",
    "            if val <= processed_dat.max()/100*highttrash_perc or np.isnan(val):\n",
    "                new_processed_dat.append(0)\n",
    "            else: new_processed_dat.append(val)\n",
    "        processed_dat = pd.Series(new_processed_dat)\n",
    "        \n",
    "    \n",
    "    \n",
    "    derivbool = False # toggels if vector should be analysed by doing derivation.\n",
    "    if derivbool:\n",
    "        deriv_dat=np.sign(pd.Series(processed_dat).diff())\n",
    "\n",
    "        if filter_plate:\n",
    "            # only usefull when back and frontplate are part of picture\n",
    "            #removing front and back plate signal\n",
    "            iter1=filterplate(deriv_dat)\n",
    "            iter2 = filterplate(np.array(iter1[::-1]*-1))[::-1]*-1\n",
    "            deriv_dat = iter2\n",
    "            \n",
    "    else:\n",
    "        peaks, _ = scipy.signal.find_peaks(processed_dat, height=0)\n",
    "        \n",
    "    #plotting images\n",
    "    fig, axs = plt.subplots(1,4,figsize=(10,5))\n",
    "    bases=[]\n",
    "    for i in range(len (axs)):\n",
    "        bases.append(axs[i].transData)\n",
    "    rot = transforms.Affine2D().rotate_deg(90)\n",
    "    axs[0].imshow(img_orig, aspect = 18)\n",
    "    axs[0].title.set_text(f\"Original Image\")\n",
    "    axs[1].imshow(img, aspect = 18)\n",
    "    axs[1].title.set_text(f\"B/W Image\")\n",
    "    \n",
    "    axs[2].plot(plotdat,transform= rot + bases[2])\n",
    "    axs[2].title.set_text(f\"Accum Pixel Val\\nHightThrPerc={highttrash_perc}%\")\n",
    "    #axs[2].plot(processed_dat, transform= rot + bases[2])\n",
    "    #axs[2].title.set_text(f\"Processed with ma={moving_average}\")\n",
    "    \n",
    "    if derivbool:\n",
    "        axs[3].plot(deriv_dat, transform= rot + bases[3])\n",
    "        axs[3].title.set_text(\"Filtered Sign change \\nof 1st Deriv\")\n",
    "    else: \n",
    "        axs[3].plot(processed_dat, transform= rot + bases[3])\n",
    "        axs[3].plot(peaks, processed_dat[peaks], \"x\", transform= rot + bases[3])\n",
    "        axs[3].title.set_text(f\"Local Maxima = {len(peaks)}\")\n",
    "    \n",
    "    if savefig:\n",
    "        fig.savefig(gen_filename(outputpath, \"imageProcessed\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a71175e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### imglstthr=get_imagepath(\"imdata/thresholded/\")\n",
    "imglstthr.sort()\n",
    "imglstorig=get_imagepath(dir_cropped)\n",
    "imglstorig.sort()\n",
    "picturenr = IntSlider(min=0, max=len(imglstthr)-1, step=1, value=4)\n",
    "highttrash_perc = IntSlider(min = 1, max=100, step=1, value=10)\n",
    "masld = IntSlider(min = 1, max=30, step=1, value=10)\n",
    "\n",
    "def img_process1_caller(imagenr=0, highttrash_perc=10, moving_average=10, filter_plate=False):\n",
    "    imgProcess1(imglstorig[imagenr], imglstthr[imagenr], highttrash_perc=highttrash_perc, moving_average=moving_average, filter_plate=filter_plate)\n",
    "_=interact(img_process1_caller,imagenr=picturenr, highttrash_perc=highttrash_perc, moving_average = masld)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c180b81e",
   "metadata": {},
   "source": [
    "In the graphic the stages of the processing can be seen.\n",
    "1. Accumulation of all pixel values per row\n",
    "1. Smoothening with Moving Average and applying a threshold value to filter out noise\n",
    "1. Analysing the sign changes of the 1st deviation and cutting out the first and last -1 to 1 sequence\n",
    "--> As a result with the right parameters 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "435e24b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "vals2save={\n",
    "        \"threshold\": highttrash_perc.value,\n",
    "        \"movingaverage\": masld.value\n",
    "        }\n",
    "save_params(\"Processing1\", vals2save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d57e3d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_processed = os.path.join(dst_path, \"processed\")\n",
    "clean_dir(dir_processed)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
